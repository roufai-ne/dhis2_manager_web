# üß† Prompts d'Int√©gration - TCD vers Template DHIS2

## Table des mati√®res
1. [Prompt Principal - Int√©gration Compl√®te](#prompt-1)
2. [Prompt Analyse de Code Existant](#prompt-2)
3. [Prompt Refactoring et Am√©lioration](#prompt-3)
4. [Prompt D√©bogage et Diagnostic](#prompt-4)
5. [Prompt Extension pour Nouveaux Datasets](#prompt-5)
6. [Annexe - Documentation Technique Compl√®te](#annexe)

---

<a name="prompt-1"></a>
## üìå PROMPT 1 : Int√©gration Compl√®te dans une Application Existante

```
Tu es un expert en d√©veloppement Python sp√©cialis√© dans les syst√®mes d'information sanitaire et √©ducatif, particuli√®rement DHIS2. Tu dois int√©grer un algorithme de traitement de donn√©es TCD (Tableaux Crois√©s Dynamiques) vers des templates DHIS2 dans une application existante.

## CONTEXTE DU PROJET

L'application existante permet de remplir des templates DHIS2 √† partir de donn√©es TCD Excel, mais le r√©sultat actuel n'est pas satisfaisant. Tu dois int√©grer un nouvel algorithme robuste qui r√©sout les probl√®mes identifi√©s.

## PROBL√àMES COURANTS √Ä R√âSOUDRE

1. **Probl√®mes de normalisation des donn√©es**
   - Les tranches d'√¢ge ont des formats incoh√©rents : "[ 20 - 22 [", "[20-22[", "20 - 22"
   - Les CategoryOptionCombo (COC) ont des espaces et tabulations variables
   - Les apostrophes typographiques (') vs droites (') causent des erreurs de matching

2. **Probl√®mes de mapping**
   - Les noms d'√©tablissements sont des acronymes dans les TCD mais des noms complets dans les templates
   - Les DataElements ont des variations orthographiques ("2√®me" vs "2e", "1√®re" vs "1ere")
   - Les cellules fusionn√©es dans les TCD cr√©ent des NaN qu'il faut propager

3. **Probl√®mes de structure**
   - Les templates DHIS2 ont un header √† la ligne 5 (index 5)
   - Les TCD ont un header √† la ligne 2 (index 2)
   - La derni√®re colonne du TCD contient toujours les valeurs √† ins√©rer

## ALGORITHME √Ä INT√âGRER

### √âtape 1 : Normalisation des donn√©es

```python
def normaliser_tranche_age(s):
    """
    Normalise une tranche d'√¢ge vers un format standard.
    
    R√®gles:
    - '[ 20 - 22 [' ‚Üí '20-22'
    - '40 ans et plus' ‚Üí '40+'
    - '- 18 ans' ou 'moins de 18' ‚Üí '-18'
    - 'ND' ou 'Non D√©fini' ‚Üí 'ND'
    
    Algorithme:
    1. Nettoyer les espaces
    2. D√©tecter les cas sp√©ciaux (40+, -18, ND)
    3. Extraire les bornes num√©riques avec regex
    4. Retourner le format normalis√© 'borne1-borne2'
    """
    if pd.isna(s):
        return None
    s = str(s).strip()
    
    # Cas sp√©ciaux
    if '40 ans' in s.lower() or '40+' in s.lower():
        return '40+'
    if '18 ans' in s.lower() or re.match(r'^-\s*18', s):
        return '-18'
    if 'ND' in s.upper():
        return 'ND'
    
    # Extraction des bornes
    match = re.search(r'\[?\s*(\d+)\s*[-‚Äì]\s*(\d+)\s*\[?', s)
    if match:
        return f"{match.group(1)}-{match.group(2)}"
    return s


def normaliser_coc(coc):
    """
    Normalise un CategoryOptionCombo.
    
    Formats d'entr√©e possibles:
    - 'F | [20 - 22[' ‚Üí 'F|20-22'
    - 'M | [22- 24[\t' ‚Üí 'M|22-24'
    - '- 18 ans | F' ‚Üí 'F|-18'
    - '40 ans +\t | M' ‚Üí 'M|40+'
    
    Algorithme:
    1. Supprimer tabs et normaliser espaces
    2. D√©tecter le format (SEXE | AGE ou AGE | SEXE)
    3. Extraire sexe et √¢ge
    4. Normaliser l'√¢ge
    5. Retourner 'SEXE|AGE_NORMALISE'
    """
    if pd.isna(coc):
        return None
    s = str(coc).strip().replace('\t', ' ')
    s = re.sub(r'\s+', ' ', s)
    
    # Format 1: "X | [NN - NN["
    match1 = re.match(r'^([FM])\s*\|\s*(.+)$', s)
    if match1:
        return f"{match1.group(1)}|{normaliser_tranche_age(match1.group(2))}"
    
    # Format 2: "- 18 ans | X" ou "40 ans + | X"
    match2 = re.match(r'^(.+)\s*\|\s*([FM])$', s)
    if match2:
        return f"{match2.group(2)}|{normaliser_tranche_age(match2.group(1))}"
    
    return s
```

### √âtape 2 : Construction des mappings dynamiques

```python
def construire_mapping_etablissements(df_template, patterns):
    """
    Construit le mapping √©tablissements en extrayant les noms EXACTS du template.
    
    Principe cl√©: Ne jamais coder en dur les noms avec apostrophes ou caract√®res sp√©ciaux.
    Extraire dynamiquement depuis le template pour √©viter les probl√®mes d'encodage.
    
    Args:
        df_template: DataFrame du template DHIS2
        patterns: Dict {'ACRONYME': 'partie_du_nom_√†_chercher'}
    
    Returns:
        Dict {'ACRONYME': 'nom_exact_du_template'}
    """
    # Extraire les noms uniques et les normaliser
    noms_template = {
        str(n).strip(): n 
        for n in df_template['orgUnitName'].unique()
        if pd.notna(n)
    }
    
    mapping = {}
    for acronyme, pattern in patterns.items():
        for nom_norm, nom_original in noms_template.items():
            if pattern.lower() in nom_norm.lower():
                mapping[acronyme] = nom_norm
                break
    
    return mapping
```

### √âtape 3 : Index de recherche optimis√©

```python
def construire_index_recherche(df_template):
    """
    Construit un index de recherche rapide bas√© sur des cl√©s normalis√©es.
    
    Cl√© de recherche: "SECTION|DATA_ELEMENT|ETABLISSEMENT|COC_NORMALISE"
    
    Avantages:
    - Recherche O(1) au lieu de O(n)
    - Ind√©pendant des variations de format
    - Facilite le d√©bogage (cl√©s lisibles)
    """
    # Ajouter colonnes normalis√©es
    df_template['_coc_norm'] = df_template['categoryOptionComboName'].apply(normaliser_coc)
    df_template['_org_norm'] = df_template['orgUnitName'].apply(lambda x: str(x).strip() if pd.notna(x) else None)
    
    # Construire la cl√©
    df_template['_cle'] = (
        df_template['section'].fillna('').str.strip() + '|' +
        df_template['dataElementName'].fillna('').str.strip() + '|' +
        df_template['_org_norm'].fillna('') + '|' +
        df_template['_coc_norm'].fillna('')
    )
    
    # Cr√©er l'index
    return {row['_cle']: idx for idx, row in df_template.iterrows()}
```

### √âtape 4 : Traitement des TCD avec propagation des NaN

```python
def traiter_onglet_tcd(df_tcd, col_etablissement, col_age, col_sexe, col_data, mapping_etab, mapping_de, index_recherche, df_template):
    """
    Traite un onglet TCD et ins√®re les valeurs dans le template.
    
    Points critiques:
    1. Propager les NaN (cellules fusionn√©es Excel)
    2. Ignorer les lignes "Total"
    3. La derni√®re colonne contient les valeurs
    4. Construire la cl√© de recherche normalis√©e
    5. Collecter les erreurs pour le rapport
    """
    # Supprimer les totaux
    df_tcd = df_tcd[~df_tcd[col_etablissement].astype(str).str.contains('Total', na=False)]
    
    # CRITIQUE: Propager les valeurs des cellules fusionn√©es
    df_tcd[col_etablissement] = df_tcd[col_etablissement].ffill()
    df_tcd[col_age] = df_tcd[col_age].ffill()
    df_tcd[col_sexe] = df_tcd[col_sexe].ffill()
    
    # Derni√®re colonne = valeurs
    col_valeur = df_tcd.columns[-1]
    
    stats = {'valeurs': 0, 'erreurs': 0}
    erreurs = []
    
    for idx, row in df_tcd.iterrows():
        etab = str(row[col_etablissement]).strip()
        age = row[col_age]
        sexe = row[col_sexe]
        data_elem = str(row[col_data]).strip()
        valeur = row[col_valeur]
        
        # Ignorer les lignes sans valeur
        if pd.isna(valeur) or valeur == 0:
            continue
        
        # Mapper l'√©tablissement
        etab_template = mapping_etab.get(etab)
        if etab_template is None:
            erreurs.append({'type': 'etablissement', 'valeur': etab, 'count': int(valeur)})
            continue
        
        # Mapper le data element
        mapping = mapping_de.get(data_elem)
        if mapping is None:
            erreurs.append({'type': 'data_element', 'valeur': data_elem, 'count': int(valeur)})
            continue
        
        section, de_template = mapping
        
        # Construire le COC normalis√©
        sexe = str(sexe).strip().upper()
        age_norm = normaliser_tranche_age(age)
        coc_norm = f"{sexe}|{age_norm}"
        
        # Construire la cl√© et rechercher
        cle = f"{section}|{de_template}|{etab_template}|{coc_norm}"
        
        if cle in index_recherche:
            idx_template = index_recherche[cle]
            df_template.at[idx_template, 'value'] = int(valeur)
            stats['valeurs'] += 1
        else:
            erreurs.append({'type': 'combinaison', 'cle': cle, 'valeur': int(valeur)})
            stats['erreurs'] += 1
    
    return stats, erreurs
```

## STRUCTURE DE DONN√âES ATTENDUE

### Template DHIS2 (colonnes)
| Colonne | Description |
|---------|-------------|
| section | Nom de la section (Cycle, Nationalit√©, etc.) |
| dataElementName | Nom du data element |
| dataElement | UID DHIS2 du data element |
| orgUnitName | Nom de l'√©tablissement |
| orgUnit | UID DHIS2 de l'√©tablissement |
| categoryOptionComboName | Combinaison SEXE + AGE |
| categoryOptionCombo | UID DHIS2 du COC |
| value | VALEUR √Ä REMPLIR |
| period | P√©riode (ex: 2023) |

### TCD (colonnes standards)
| Colonne | Description |
|---------|-------------|
| NOM_ETAB | Acronyme de l'√©tablissement |
| GROUP_AGE | Tranche d'√¢ge |
| SEXE | F ou M |
| [VARIABLE] | Data element (CYCLE, DIPL√îME, etc.) |
| Nombre de... | Valeur (derni√®re colonne) |

## INSTRUCTIONS D'INT√âGRATION

1. **Analyser le code existant** pour identifier les points d'int√©gration
2. **Remplacer les fonctions de normalisation** par celles fournies
3. **Impl√©menter l'index de recherche** pour optimiser les performances
4. **Ajouter la propagation des NaN** pour g√©rer les cellules fusionn√©es
5. **Extraire dynamiquement les noms** depuis le template (ne pas coder en dur)
6. **G√©n√©rer un rapport d√©taill√©** des erreurs

## CODE EXISTANT √Ä ANALYSER

[COLLER ICI LE CODE EXISTANT DE L'APPLICATION]

## T√ÇCHE

Analyse le code existant et propose une int√©gration intelligente de l'algorithme d√©crit ci-dessus. Identifie :
1. Les fonctions √† remplacer
2. Les fonctions √† am√©liorer
3. Les nouvelles fonctions √† ajouter
4. Les modifications de structure n√©cessaires

Fournis le code refactoris√© complet avec des commentaires expliquant chaque modification.
```

---

<a name="prompt-2"></a>
## üìå PROMPT 2 : Analyse et Diagnostic du Code Existant

```
Tu es un expert en analyse de code Python et en syst√®mes DHIS2. Tu dois analyser un code existant de traitement TCD vers template DHIS2 qui ne fonctionne pas correctement.

## PROBL√àMES CONNUS

L'application actuelle pr√©sente les probl√®mes suivants :
- Les valeurs ne sont pas correctement ins√©r√©es dans le template
- Certains √©tablissements ne sont pas reconnus
- Les tranches d'√¢ge ne matchent pas
- Des donn√©es sont perdues sans explication

## POINTS DE V√âRIFICATION CRITIQUES

Analyse le code en v√©rifiant ces points pr√©cis :

### 1. Normalisation des cha√Ænes
```python
# ‚ùå MAUVAIS - Comparaison directe
if etab_tcd == etab_template:

# ‚úÖ BON - Normalisation avant comparaison
if etab_tcd.strip().lower() == etab_template.strip().lower():
```

### 2. Gestion des apostrophes
```python
# ‚ùå MAUVAIS - Apostrophe cod√©e en dur (peut √™tre ' ou ')
nom = "Ecole d'Economie"

# ‚úÖ BON - Extraction dynamique depuis le template
noms_template = df_template['orgUnitName'].unique()
nom = next((n for n in noms_template if 'Economie' in n), None)
```

### 3. Gestion des cellules fusionn√©es Excel
```python
# ‚ùå MAUVAIS - Ignorer les NaN
df = df.dropna()

# ‚úÖ BON - Propager les valeurs
df['NOM_ETAB'] = df['NOM_ETAB'].ffill()  # Forward fill
```

### 4. Format des tranches d'√¢ge
```python
# ‚ùå MAUVAIS - Format rigide
if age == '[20 - 22[':

# ‚úÖ BON - Normalisation flexible
def normaliser_age(s):
    match = re.search(r'(\d+)\s*[-‚Äì]\s*(\d+)', s)
    if match:
        return f"{match.group(1)}-{match.group(2)}"
```

### 5. Recherche dans le template
```python
# ‚ùå MAUVAIS - Recherche lin√©aire O(n) pour chaque ligne
for idx, row in df_template.iterrows():
    if row['section'] == section and row['dataElement'] == de:
        ...

# ‚úÖ BON - Index de recherche O(1)
index = {f"{row['section']}|{row['dataElement']}": idx for idx, row in df_template.iterrows()}
if cle in index:
    idx = index[cle]
```

### 6. Gestion des espaces et tabs
```python
# ‚ùå MAUVAIS - Ne pas nettoyer
coc = row['categoryOptionComboName']

# ‚úÖ BON - Nettoyer tabs et espaces multiples
coc = row['categoryOptionComboName'].replace('\t', ' ')
coc = re.sub(r'\s+', ' ', coc).strip()
```

## CODE √Ä ANALYSER

[COLLER LE CODE EXISTANT ICI]

## T√ÇCHE

1. Identifie TOUS les probl√®mes dans le code selon les points ci-dessus
2. Pour chaque probl√®me, explique :
   - O√π il se trouve (ligne/fonction)
   - Pourquoi c'est un probl√®me
   - Comment le corriger
3. Classe les probl√®mes par criticit√© (Critique, Important, Mineur)
4. Propose un plan de correction ordonn√©

Format de sortie attendu :
```
## PROBL√àME 1 [CRITIQUE]
- Localisation: fonction xyz(), ligne XX
- Description: ...
- Impact: ...
- Correction: ...
```
```

---

<a name="prompt-3"></a>
## üìå PROMPT 3 : Refactoring et Am√©lioration de Performance

```
Tu es un expert en refactoring Python et optimisation de performance. Tu dois am√©liorer un code de traitement de donn√©es TCD vers DHIS2.

## OBJECTIFS DU REFACTORING

1. **Performance** : Le code doit traiter 10 000+ lignes en moins de 5 secondes
2. **Maintenabilit√©** : Code modulaire et bien document√©
3. **Robustesse** : Gestion compl√®te des erreurs et cas limites
4. **Extensibilit√©** : Facile √† adapter pour de nouveaux datasets

## ARCHITECTURE CIBLE

```
tcd_processor/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ config.py          # Configuration et mappings
‚îú‚îÄ‚îÄ normalizers.py     # Fonctions de normalisation
‚îú‚îÄ‚îÄ processor.py       # Classe principale TCDProcessor
‚îú‚îÄ‚îÄ reporters.py       # G√©n√©ration de rapports
‚îî‚îÄ‚îÄ utils.py           # Utilitaires
```

## PATTERNS √Ä IMPL√âMENTER

### Pattern 1 : Configuration externalis√©e
```python
@dataclass
class MappingConfig:
    """Configuration des mappings - modifiable sans changer le code."""
    etablissements_patterns: Dict[str, str]
    onglets_mapping: Dict[str, str]
    data_elements_manuels: Dict[str, Tuple[str, str]]
    template_header_row: int = 5
    tcd_header_row: int = 2
```

### Pattern 2 : Classe de normalisation statique
```python
class Normalizer:
    """M√©thodes statiques de normalisation - r√©utilisables."""
    
    @staticmethod
    def normaliser_tranche_age(s: Any) -> Optional[str]:
        ...
    
    @staticmethod
    def normaliser_coc(coc: Any) -> Optional[str]:
        ...
```

### Pattern 3 : Processeur avec cha√Ænage fluide
```python
processor = TCDProcessor(template, tcd, config)
processor.load().process().save(output)

# Ou √©tape par √©tape pour debug
processor.load()
processor.build_mappings()
processor.build_index()
processor.process_all_sheets()
print(processor.stats)
processor.save(output)
```

### Pattern 4 : Statistiques structur√©es
```python
@dataclass
class ProcessingStats:
    lignes_traitees: int = 0
    valeurs_inserees: int = 0
    etablissements_non_mappes: Dict[str, int] = field(default_factory=dict)
    combinaisons_non_trouvees: List[Dict] = field(default_factory=list)
    
    def to_dataframe(self) -> pd.DataFrame:
        """Convertit en DataFrame pour export."""
        ...
```

## OPTIMISATIONS REQUISES

### 1. Vectorisation Pandas
```python
# ‚ùå LENT - It√©ration ligne par ligne
for idx, row in df.iterrows():
    df.at[idx, 'norm'] = normaliser(row['col'])

# ‚úÖ RAPIDE - Vectorisation
df['norm'] = df['col'].apply(normaliser)
```

### 2. Index de recherche avec dict
```python
# ‚ùå LENT - O(n) par recherche
mask = (df['a'] == val_a) & (df['b'] == val_b)
result = df[mask]

# ‚úÖ RAPIDE - O(1) avec index
index = {(row['a'], row['b']): idx for idx, row in df.iterrows()}
if (val_a, val_b) in index:
    result = df.loc[index[(val_a, val_b)]]
```

### 3. Compilation regex une seule fois
```python
# ‚ùå LENT - Recompilation √† chaque appel
def func(s):
    return re.search(r'\d+', s)

# ‚úÖ RAPIDE - Compilation unique
PATTERN_DIGITS = re.compile(r'\d+')
def func(s):
    return PATTERN_DIGITS.search(s)
```

## CODE ACTUEL √Ä REFACTORISER

[COLLER LE CODE ICI]

## T√ÇCHE

1. Refactorise le code selon l'architecture cible
2. Impl√©mente les patterns d√©crits
3. Applique les optimisations de performance
4. Ajoute une gestion compl√®te des erreurs
5. Documente chaque fonction avec docstrings
6. Ajoute des type hints partout

Fournis le code complet refactoris√©, organis√© en modules.
```

---

<a name="prompt-4"></a>
## üìå PROMPT 4 : D√©bogage et Diagnostic des Erreurs

```
Tu es un expert en d√©bogage Python. Tu dois diagnostiquer pourquoi un traitement TCD vers DHIS2 ne produit pas les r√©sultats attendus.

## SYMPT√îMES RAPPORT√âS

- X valeurs attendues mais seulement Y ins√©r√©es
- Certains √©tablissements sont ignor√©s sans raison apparente
- Le rapport montre des "combinaisons non trouv√©es" qui devraient exister

## M√âTHODOLOGIE DE DIAGNOSTIC

### √âtape 1 : V√©rifier les donn√©es d'entr√©e
```python
# Afficher les valeurs uniques pour identifier les variations
print("=== √âTABLISSEMENTS DANS LE TCD ===")
print(df_tcd['NOM_ETAB'].unique())

print("\n=== √âTABLISSEMENTS DANS LE TEMPLATE ===")
for org in df_template['orgUnitName'].unique():
    print(f"  '{org}' -> repr: {repr(org)}")
```

### √âtape 2 : Comparer caract√®re par caract√®re
```python
def compare_strings(s1, s2):
    """Compare deux cha√Ænes caract√®re par caract√®re."""
    print(f"String 1: '{s1}' (len={len(s1)})")
    print(f"String 2: '{s2}' (len={len(s2)})")
    
    for i, (c1, c2) in enumerate(zip(s1, s2)):
        if c1 != c2:
            print(f"  Diff at pos {i}: '{c1}' (ord={ord(c1)}) vs '{c2}' (ord={ord(c2)})")
    
    if len(s1) != len(s2):
        print(f"  Length diff: {len(s1)} vs {len(s2)}")
```

### √âtape 3 : Tracer une ligne sp√©cifique
```python
def debug_ligne(row, mapping_etab, mapping_de, index_recherche):
    """Trace le traitement d'une ligne pour comprendre o√π √ßa √©choue."""
    print(f"\n=== DEBUG LIGNE ===")
    print(f"√âtablissement TCD: '{row['NOM_ETAB']}'")
    
    etab_template = mapping_etab.get(row['NOM_ETAB'].strip())
    print(f"√âtablissement mapp√©: {etab_template}")
    if etab_template is None:
        print("  ‚ùå √âCHEC: √âtablissement non trouv√© dans le mapping")
        print(f"  Mappings disponibles: {list(mapping_etab.keys())}")
        return
    
    data_elem = row['CYCLE'].strip()  # Adapter selon l'onglet
    mapping = mapping_de.get(data_elem)
    print(f"Data element TCD: '{data_elem}'")
    print(f"Data element mapp√©: {mapping}")
    if mapping is None:
        print("  ‚ùå √âCHEC: Data element non trouv√© dans le mapping")
        return
    
    section, de_template = mapping
    
    sexe = str(row['SEXE']).strip().upper()
    age_norm = normaliser_tranche_age(row['GROUP_AGE'])
    coc_norm = f"{sexe}|{age_norm}"
    print(f"COC construit: '{coc_norm}'")
    
    cle = f"{section}|{de_template}|{etab_template}|{coc_norm}"
    print(f"Cl√© de recherche: '{cle}'")
    
    if cle in index_recherche:
        print(f"  ‚úÖ TROUV√â √† l'index {index_recherche[cle]}")
    else:
        print("  ‚ùå √âCHEC: Cl√© non trouv√©e dans l'index")
        # Chercher des cl√©s similaires
        similaires = [k for k in index_recherche.keys() if etab_template in k and de_template in k]
        print(f"  Cl√©s similaires: {similaires[:5]}")
```

### √âtape 4 : G√©n√©rer un rapport de diagnostic
```python
def generer_diagnostic(df_tcd, df_template, mapping_etab, mapping_de):
    """G√©n√®re un rapport complet de diagnostic."""
    rapport = {
        'etab_tcd_non_mappes': [],
        'de_tcd_non_mappes': [],
        'coc_template_uniques': set(),
        'coc_tcd_uniques': set(),
    }
    
    # √âtablissements TCD non mapp√©s
    for etab in df_tcd['NOM_ETAB'].dropna().unique():
        if etab.strip() not in mapping_etab:
            rapport['etab_tcd_non_mappes'].append(etab)
    
    # COC uniques dans le template (normalis√©s)
    for coc in df_template['categoryOptionComboName'].dropna().unique():
        rapport['coc_template_uniques'].add(normaliser_coc(coc))
    
    # COC uniques dans le TCD
    for _, row in df_tcd.iterrows():
        if pd.notna(row['SEXE']) and pd.notna(row['GROUP_AGE']):
            sexe = str(row['SEXE']).strip().upper()
            age = normaliser_tranche_age(row['GROUP_AGE'])
            rapport['coc_tcd_uniques'].add(f"{sexe}|{age}")
    
    # COC dans TCD mais pas dans template
    rapport['coc_manquants'] = rapport['coc_tcd_uniques'] - rapport['coc_template_uniques']
    
    return rapport
```

## ERREUR √Ä DIAGNOSTIQUER

[D√âCRIRE L'ERREUR SP√âCIFIQUE OU COLLER LES LOGS]

## CODE CONCERN√â

[COLLER LE CODE]

## DONN√âES D'EXEMPLE

[COLLER UN √âCHANTILLON DES DONN√âES TCD ET TEMPLATE]

## T√ÇCHE

1. Analyse les sympt√¥mes et le code
2. Identifie la cause racine probable
3. Propose des tests de diagnostic √† ex√©cuter
4. Fournis le correctif avec explication
```

---

<a name="prompt-5"></a>
## üìå PROMPT 5 : Extension pour Nouveaux Datasets

```
Tu es un expert en d√©veloppement Python et DHIS2. Tu dois √©tendre un syst√®me de traitement TCD existant pour supporter de nouveaux datasets.

## SYST√àME EXISTANT

Le syst√®me actuel traite les datasets suivants :
- Effectifs √©tudiants par cycle
- Effectifs par nationalit√©
- Effectifs par ann√©e d'√©tude
- Effectifs par dipl√¥me

## NOUVEAU DATASET √Ä INT√âGRER

[D√âCRIRE LE NOUVEAU DATASET]

Exemple de structure :
- Nom du dataset : [NOM]
- Sections : [LISTE DES SECTIONS]
- Data elements : [LISTE]
- Dimensions : [AGE, SEXE, AUTRES...]

## √âTAPES D'EXTENSION

### 1. Analyser le nouveau template DHIS2
```python
def analyser_template(template_path):
    """Analyse un template pour comprendre sa structure."""
    df = pd.read_excel(template_path, sheet_name="Donn√©es", header=5)
    
    print("=== STRUCTURE DU TEMPLATE ===")
    print(f"Colonnes: {df.columns.tolist()}")
    print(f"Lignes: {len(df)}")
    
    print("\n=== SECTIONS ===")
    for section in df['section'].dropna().unique():
        print(f"\n  {section}:")
        des = df[df['section'] == section]['dataElementName'].unique()
        for de in des:
            print(f"    - {de}")
    
    print("\n=== CATEGORY OPTION COMBOS ===")
    for coc in df['categoryOptionComboName'].dropna().unique():
        print(f"  '{coc}' -> repr: {repr(coc)}")
    
    print("\n=== ORG UNITS ===")
    for org in df['orgUnitName'].dropna().unique():
        print(f"  '{org}'")
    
    return df
```

### 2. Analyser le nouveau TCD
```python
def analyser_tcd(tcd_path, sheet_name):
    """Analyse un onglet TCD pour comprendre sa structure."""
    df = pd.read_excel(tcd_path, sheet_name=sheet_name, header=2)
    
    print(f"=== STRUCTURE TCD: {sheet_name} ===")
    print(f"Colonnes: {df.columns.tolist()}")
    
    print("\n=== VALEURS UNIQUES PAR COLONNE ===")
    for col in df.columns:
        uniques = df[col].dropna().unique()
        print(f"\n  {col} ({len(uniques)} valeurs):")
        for v in uniques[:10]:
            print(f"    - '{v}'")
        if len(uniques) > 10:
            print(f"    ... et {len(uniques) - 10} autres")
    
    return df
```

### 3. Cr√©er les nouveaux mappings
```python
# Ajouter dans MappingConfig

# Nouveaux √©tablissements
config.etablissements_patterns['NOUVEAU_CODE'] = 'Partie du nom'

# Nouvel onglet TCD
config.onglets_mapping['nouvel_onglet'] = 'NOM_COLONNE_DATA_ELEMENT'

# Nouveaux data elements
config.data_elements_manuels['VALEUR_TCD'] = ('Section Template', 'DataElement Template')
```

### 4. G√©rer les nouvelles dimensions (si diff√©rentes de SEXE|AGE)
```python
def construire_coc_personnalise(row, dimensions):
    """
    Construit un COC pour des dimensions personnalis√©es.
    
    Args:
        row: Ligne du TCD
        dimensions: Liste des colonnes √† combiner ['DIM1', 'DIM2']
    
    Returns:
        COC normalis√© "DIM1|DIM2"
    """
    parties = []
    for dim in dimensions:
        val = row.get(dim)
        if pd.notna(val):
            parties.append(normaliser_dimension(str(val).strip(), dim))
        else:
            return None
    return '|'.join(parties)
```

## TEMPLATE DU NOUVEAU DATASET

[COLLER UN EXTRAIT DU NOUVEAU TEMPLATE]

## TCD DU NOUVEAU DATASET

[COLLER UN EXTRAIT DU NOUVEAU TCD]

## T√ÇCHE

1. Analyse les structures du nouveau template et TCD
2. Identifie les mappings n√©cessaires
3. D√©termine si de nouvelles normalisations sont requises
4. Propose les modifications du code existant
5. Fournis le code d'extension complet
```

---

<a name="annexe"></a>
## üìö ANNEXE : Documentation Technique Compl√®te

### A. Algorithme de Traitement - Vue d'ensemble

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   TEMPLATE      ‚îÇ     ‚îÇ   PROCESSEUR     ‚îÇ     ‚îÇ      TCD        ‚îÇ
‚îÇ    DHIS2        ‚îÇ     ‚îÇ                  ‚îÇ     ‚îÇ    (Excel)      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                       ‚îÇ                        ‚îÇ
         ‚îÇ  1. Charger           ‚îÇ                        ‚îÇ
         ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                        ‚îÇ
         ‚îÇ                       ‚îÇ  2. Charger            ‚îÇ
         ‚îÇ                       ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫‚îÇ
         ‚îÇ                       ‚îÇ                        ‚îÇ
         ‚îÇ  3. Extraire noms     ‚îÇ                        ‚îÇ
         ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                        ‚îÇ
         ‚îÇ     exacts            ‚îÇ                        ‚îÇ
         ‚îÇ                       ‚îÇ                        ‚îÇ
         ‚îÇ  4. Construire        ‚îÇ                        ‚îÇ
         ‚îÇ     mappings          ‚îÇ                        ‚îÇ
         ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                        ‚îÇ
         ‚îÇ                       ‚îÇ                        ‚îÇ
         ‚îÇ  5. Construire        ‚îÇ                        ‚îÇ
         ‚îÇ     index O(1)        ‚îÇ                        ‚îÇ
         ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                        ‚îÇ
         ‚îÇ                       ‚îÇ                        ‚îÇ
         ‚îÇ                       ‚îÇ  6. Pour chaque        ‚îÇ
         ‚îÇ                       ‚îÇ     onglet TCD         ‚îÇ
         ‚îÇ                       ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
         ‚îÇ                       ‚îÇ                        ‚îÇ
         ‚îÇ                       ‚îÇ  7. Propager NaN       ‚îÇ
         ‚îÇ                       ‚îÇ     (ffill)            ‚îÇ
         ‚îÇ                       ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
         ‚îÇ                       ‚îÇ                        ‚îÇ
         ‚îÇ                       ‚îÇ  8. Pour chaque ligne  ‚îÇ
         ‚îÇ                       ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
         ‚îÇ                       ‚îÇ                        ‚îÇ
         ‚îÇ  9. Construire cl√©    ‚îÇ                        ‚îÇ
         ‚îÇ     normalis√©e        ‚îÇ                        ‚îÇ
         ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                        ‚îÇ
         ‚îÇ                       ‚îÇ                        ‚îÇ
         ‚îÇ  10. Rechercher &     ‚îÇ                        ‚îÇ
         ‚îÇ      ins√©rer valeur   ‚îÇ                        ‚îÇ
         ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                        ‚îÇ
         ‚îÇ                       ‚îÇ                        ‚îÇ
         ‚îÇ  11. Sauvegarder      ‚îÇ                        ‚îÇ
         ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                        ‚îÇ
         ‚îÇ                       ‚îÇ                        ‚îÇ
         ‚ñº                       ‚ñº                        ‚ñº
   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
   ‚îÇ  TEMPLATE   ‚îÇ        ‚îÇ   RAPPORT   ‚îÇ         ‚îÇ   STATS     ‚îÇ
   ‚îÇ   REMPLI    ‚îÇ        ‚îÇ   ERREURS   ‚îÇ         ‚îÇ             ‚îÇ
   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### B. Format de la Cl√© de Recherche

```
SECTION | DATA_ELEMENT | ETABLISSEMENT | COC_NORMALISE
   ‚îÇ          ‚îÇ              ‚îÇ               ‚îÇ
   ‚îÇ          ‚îÇ              ‚îÇ               ‚îî‚îÄ‚ñ∫ "F|20-22" ou "M|40+"
   ‚îÇ          ‚îÇ              ‚îÇ
   ‚îÇ          ‚îÇ              ‚îî‚îÄ‚ñ∫ Nom exact extrait du template
   ‚îÇ          ‚îÇ
   ‚îÇ          ‚îî‚îÄ‚ñ∫ Nom exact du data element
   ‚îÇ
   ‚îî‚îÄ‚ñ∫ Nom de la section (Cycle, Nationalit√©, etc.)

Exemple:
"Cycle|1er cycle|Centre Priv√© de Sant√© Publique|F|20-22"
```

### C. R√®gles de Normalisation des Tranches d'√Çge

| Entr√©e | Sortie | R√®gle |
|--------|--------|-------|
| `[ 20 - 22 [` | `20-22` | Extraction bornes |
| `[20-22[` | `20-22` | Extraction bornes |
| `20 - 22` | `20-22` | Extraction bornes |
| `[ 28 - 30 [ ` | `28-30` | Trim + extraction |
| `40 ans et plus` | `40+` | Cas sp√©cial 40+ |
| `40 ans +` | `40+` | Cas sp√©cial 40+ |
| `- 18 ans` | `-18` | Cas sp√©cial moins de 18 |
| `moins de 18` | `-18` | Cas sp√©cial moins de 18 |
| `ND` | `ND` | Non d√©fini |

### D. Gestion des Erreurs - Types et Causes

| Type d'erreur | Cause probable | Solution |
|---------------|----------------|----------|
| √âtablissement non mapp√© | Acronyme inconnu | Ajouter dans `etablissements_patterns` |
| Data element non mapp√© | Variation orthographique | Ajouter dans `data_elements_manuels` |
| Combinaison non trouv√©e | Template incomplet | V√©rifier si la combinaison existe dans DHIS2 |
| Valeur NaN | Cellule fusionn√©e non propag√©e | V√©rifier `ffill()` |
| Apostrophe mismatch | Encodage diff√©rent | Extraire dynamiquement depuis le template |

### E. Configuration Recommand√©e

```python
config = MappingConfig(
    # Mapping √©tablissements : ACRONYME -> partie du nom √† chercher
    etablissements_patterns={
        'CPSP': 'Centre Priv√© de Sant√© Publique',
        'ESEG': 'Economie et de Gestion',
        'UAZ': 'UNIVERSITE AGADEZ',
        # ... autres
    },
    
    # Mapping onglets : nom_onglet -> colonne_data_element
    onglets_mapping={
        'cycle': 'CYCLE',
        'nationalit√©': 'GROUP_NAT',
        'annee_etud': 'ANNE_ETU',
        'diplome': 'DIPL√îME',
    },
    
    # Mappings manuels pour les variations orthographiques
    data_elements_manuels={
        '2√®me cycle': ('Cycle', '2e cycle'),
        '1√®re ann√©e': ("Niveau d'√©tude", '1ere ann√©e'),
        'NIGER': ('Nationalit√©', 'Niger'),
        # ... autres
    },
    
    # Positions des headers
    template_header_row=5,
    tcd_header_row=2,
)
```

---

## üîß Utilisation des Prompts

1. **Pour une nouvelle int√©gration** : Utiliser le Prompt 1
2. **Pour diagnostiquer un probl√®me** : Utiliser les Prompts 2 et 4
3. **Pour am√©liorer les performances** : Utiliser le Prompt 3
4. **Pour ajouter un nouveau dataset** : Utiliser le Prompt 5

Chaque prompt est con√ßu pour √™tre auto-suffisant et contient toute la logique m√©tier n√©cessaire.